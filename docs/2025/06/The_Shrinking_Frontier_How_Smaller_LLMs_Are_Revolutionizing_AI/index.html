<!DOCTYPE html><html lang="en"><head><!-- hexo injector head_begin start --><!-- Google tag (gtag.js) begins-->
    <script async="" src="https://www.googletagmanager.com/gtag/js?id=G-3DZR3TQYCY"></script>
    <script>
      window.dataLayer = window.dataLayer || [];
      function gtag(){dataLayer.push(arguments);}
      gtag('js', new Date());
    
      gtag('config', 'G-3DZR3TQYCY');
    </script>
    <!-- Google tag (gtag.js) ends-->
    <!-- hexo injector head_begin end -->
    <meta charset="utf-8">
    <!-- security headers starts -->
    <!-- meta http-equiv="content-security-policy" content="script-src 'sha256-B5nfCL2Dym3Ba4YJFI7wB3f4vtClbrYJZ32A5erBEdg=' 'sha256-lJjk3/dvd+wXqRFjV7T5L/nXJXr5NjUjmsKSPEe+ass=';" -->
    <!-- security headers ends -->
    <!-- favicon starts -->    
    <link rel="apple-touch-icon" sizes="180x180" href="/apple-touch-icon.png">
    <link rel="icon" type="image/png" sizes="32x32" href="/favicon-32x32.png">
    <link rel="icon" type="image/png" sizes="16x16" href="/favicon-16x16.png">
    <link rel="manifest" href="/site.webmanifest">
    <link rel="mask-icon" href="/safari-pinned-tab.svg" color="#5bbad5">
    <meta name="msapplication-TileColor" content="#da532c">
    <!-- favicon ends -->
    

    
    <title>The Shrinking Frontier: How Smaller LLMs Are Revolutionizing AI | Decoding Digital Anomalies</title>
    <meta name="viewport" content="width=device-width, initial-scale=1">
    
    <meta name="keywords" content="AI">
    
    <meta name="description" content="The Shrinking Frontier: How Smaller LLMs Are Revolutionizing AI In the rapidly evolving landscape of artificial intelligence, Large Language Models (LLMs) have undergone a remarkable transformation.">
<meta property="og:type" content="article">
<meta property="og:title" content="The Shrinking Frontier: How Smaller LLMs Are Revolutionizing AI">
<meta property="og:url" content="http://neo01.com/2025/06/The_Shrinking_Frontier_How_Smaller_LLMs_Are_Revolutionizing_AI/index.html">
<meta property="og:site_name" content="Decoding Digital Anomalies">
<meta property="og:description" content="The Shrinking Frontier: How Smaller LLMs Are Revolutionizing AI In the rapidly evolving landscape of artificial intelligence, Large Language Models (LLMs) have undergone a remarkable transformation.">
<meta property="og:locale" content="en_US">
<meta property="og:image" content="http://neo01.com/2025/06/The_Shrinking_Frontier_How_Smaller_LLMs_Are_Revolutionizing_AI/banner.jpg">
<meta property="article:published_time" content="2025-06-07T16:00:00.000Z">
<meta property="article:modified_time" content="2025-09-20T13:25:15.874Z">
<meta property="article:author" content="Neo Alienson">
<meta property="article:tag" content="AI">
<meta name="twitter:card" content="summary">
<meta name="twitter:image" content="http://neo01.com/2025/06/The_Shrinking_Frontier_How_Smaller_LLMs_Are_Revolutionizing_AI/banner.jpg">
    

    
        <link rel="alternate" href="/atom.xml" title="Decoding Digital Anomalies" type="application/atom+xml">
    

    
<link rel="stylesheet" href="/libs/font-awesome/css/font-awesome.min.css">

    
<link rel="stylesheet" href="/libs/titillium-web/styles.css">


    
<link rel="stylesheet" href="/css/style.css">

    
<link rel="stylesheet" href="/css/prism-line-numbers.css">

    
<link rel="stylesheet" href="/css/prism.min.css">


    


    
    
        
<link rel="stylesheet" href="/libs/lightgallery/css/lightgallery.min.css">

    
    
        
<link rel="stylesheet" href="/libs/justified-gallery/justifiedGallery.min.css">

    


<!-- hexo injector head_end start --><script type="text/javascript" src="/js/bundle_first.js"></script><!-- hexo injector head_end end --><meta name="generator" content="Hexo 7.3.0"></head>

<body>
    <div id="wrap">
        <header id="header">
    <div id="header-outer" class="outer">
        <div class="container">
            <div class="container-inner">
                <div id="header-title">
                    <h1 class="logo-wrap">
                        <a href="/" title="Homepage" class="logo"></a>
                    </h1>
                    
                        <h2 class="subtitle-wrap">
                          
                            <p class="title">Decoding Digital Anomalies</p>
                          
                          <p class="subtitle">Sometimes the feature is the bug in the digital rabbit hole, and vice versa</p>
                        </h2>
                    
                </div>
                <div id="header-inner" class="nav-container">
                    <a id="main-nav-toggle" class="nav-icon fa fa-bars"></a>
                    <div class="nav-container-inner">
                        <ul id="main-nav">
                            
                                <li class="main-nav-list-item">
                                    <a class="main-nav-list-link" href="/">Home</a>
                                </li>
                            
                                        <ul class="main-nav-list"><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/AI/">AI</a><ul class="main-nav-list-child"><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/AI/Art-Gallery/">Art Gallery</a></li></ul></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Cybersecurity/">Cybersecurity</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Development/">Development</a></li><li class="main-nav-list-item"><a class="main-nav-list-link" href="/categories/Misc/">Misc</a></li></ul>
                                    
                                <li class="main-nav-list-item">
                                    <a class="main-nav-list-link" href="/about-me">About</a>
                                </li>
                            
                        </ul>
                        <nav id="sub-nav">
                            <div id="search-form-wrap">

    <form class="search-form">
        <input type="text" class="ins-search-input search-form-input" id="search-form-input" placeholder="Search">
        <button type="submit" title="Search" class="search-form-submit"></button>
    </form>
    <div class="ins-search">
    <div class="ins-search-mask"></div>
    <div class="ins-search-container">
        <div class="ins-input-wrapper">
            <input type="text" class="ins-search-input" id="ins-search-input" placeholder="Type something...">
            <span class="ins-close ins-selectable"><i class="fa fa-times-circle"></i></span>
        </div>
        <div class="ins-section-wrapper">
            <div class="ins-section-container"></div>
        </div>
    </div>
</div>
<script integrity="sha256-B5nfCL2Dym3Ba4YJFI7wB3f4vtClbrYJZ32A5erBEdg=">
(function (window) {
    var INSIGHT_CONFIG = {
        TRANSLATION: {
            POSTS: 'Posts',
            PAGES: 'Pages',
            CATEGORIES: 'Categories',
            TAGS: 'Tags',
            UNTITLED: '(Untitled)',
        },
        ROOT_URL: '/',
        CONTENT_URL: '/content.json',
    };
    window.INSIGHT_CONFIG = INSIGHT_CONFIG;
})(window);
</script>




</div>
                        </nav>
                    </div>
                </div>
            </div>
        </div>
    </div>
</header>
        <div class="container">
            <div class="main-body container-inner">
                <div class="main-body-inner">
                    <section id="main">
                        <div class="main-body-header">
    <h1 class="header">
    
    <a class="page-title-link" href="/categories/AI/">AI</a>
    </h1>
</div>

                        <div class="main-body-content">
                            <article id="post-2025/06/The_Shrinking_Frontier_How_Smaller_LLMs_Are_Revolutionizing_AI" class="article article-single article-type-post" itemscope="" itemprop="blogPost">
    <div class="article-inner responsive-content">
        
            <header class="article-header">
                
    
        <h1 class="article-title" itemprop="name">
        The Shrinking Frontier: How Smaller LLMs Are Revolutionizing AI
        </h1>
    

            </header>
        
        
            <div class="article-meta">
                
    <div class="article-date">
      <i class="fa fa-calendar"></i>
      <a href="/2025/06/The_Shrinking_Frontier_How_Smaller_LLMs_Are_Revolutionizing_AI/" class="article-date">
        
          Created <time datetime="2025-06-07T16:00:00.000Z" itemprop="datePublished">2025-06-08</time>
          &nbsp;<i class="fa fa-calendar"></i>
          Updated <time datetime="2025-09-20T13:25:15.874Z" itemprop="datePublished">2025-09-20</time>
        
      </a>
    </div>


                

                
    <div class="article-tag">
        <i class="fa fa-tag"></i>
        <a class="tag-link-link" href="/tags/AI/" rel="tag">AI</a>
    </div>

                

            </div>
        
        
        <div class="article-entry" itemprop="articleBody">
            <ol class="toc"><li class="toc-item toc-level-1"><a class="toc-link"><span class="toc-text">The Shrinking Frontier: How Smaller LLMs Are Revolutionizing AI</span></a><ol class="toc-child"><li class="toc-item toc-level-2"><a class="toc-link" href="#The-Trend-From-Massive-to-Miniature"><span class="toc-text">The Trend: From Massive to Miniature</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Drivers-The-Forces-Behind-Model-Compression"><span class="toc-text">Drivers: The Forces Behind Model Compression</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Benefits-The-Advantages-of-Smaller-LLMs"><span class="toc-text">Benefits: The Advantages of Smaller LLMs</span></a></li><li class="toc-item toc-level-2"><a class="toc-link" href="#Conclusion"><span class="toc-text">Conclusion</span></a></li></ol></li></ol>
            <p><img src="banner.jpg" alt=""></p>
<h1>The Shrinking Frontier: How Smaller LLMs Are Revolutionizing AI</h1>
<p>In the rapidly evolving landscape of artificial intelligence, Large Language Models (LLMs) have undergone a remarkable transformation. What began with massive models requiring enormous computational resources has shifted toward a paradigm of efficiency and accessibility. This exploration examines the emerging trend of smaller LLMs, analyzing the drivers behind this shift and the substantial benefits they offer. Drawing from recent advancements in AI research, we uncover how this trend is reshaping the field and democratizing access to powerful language processing capabilities.</p>
<h2 id="The-Trend-From-Massive-to-Miniature">The Trend: From Massive to Miniature</h2>
<p>The trajectory of LLM development has been characterized by an initial arms race toward larger and more complex models. Early breakthroughs like GPT-3, with its 175 billion parameters, demonstrated unprecedented language understanding capabilities but came at a steep cost. However, recent years have witnessed a counter-movement toward model compression and efficiency. Research institutions and tech companies are increasingly focusing on creating smaller, more streamlined models that retain much of the performance of their larger counterparts.</p>
<p>This trend is evident in the proliferation of distilled and compressed models. Techniques like knowledge distillation, where a smaller “student” model learns from a larger “teacher” model, have enabled the creation of models that are orders of magnitude smaller. For instance, DistilBERT, a distilled version of BERT, achieves 97% of the original model’s performance while being 40% smaller and 60% faster. Similarly, TinyLLaMA and other compact variants of larger models are gaining traction, offering viable alternatives for resource-constrained environments.</p>
<h2 id="Drivers-The-Forces-Behind-Model-Compression">Drivers: The Forces Behind Model Compression</h2>
<p>The shift toward smaller LLMs is propelled by a confluence of technological, economic, environmental, and societal factors. These drivers are not isolated but form an interconnected ecosystem that makes model compression both necessary and achievable. Understanding these forces provides insight into why the AI community is increasingly prioritizing efficiency over sheer scale.</p>
<h3 id="Computational-Efficiency-and-Cost-Reduction">Computational Efficiency and Cost Reduction</h3>
<p>The computational demands of training and deploying large models present significant barriers that have become increasingly untenable. Training GPT-3 required an estimated 570,000 GPU hours and cost millions of dollars, with inference costs scaling proportionally. As AI becomes more ubiquitous across industries—from healthcare to finance—these resource requirements create substantial economic hurdles. Smaller models address this by dramatically reducing both training and inference costs. For instance, a distilled model might require only 10-20% of the computational resources of its full-sized counterpart while maintaining 90-95% of the performance. This cost reduction enables startups, academic researchers, and smaller organizations to participate in AI development, fostering innovation across the ecosystem rather than concentrating it in a few well-funded entities.</p>
<h3 id="Energy-Efficiency-and-Environmental-Considerations">Energy Efficiency and Environmental Considerations</h3>
<p>The environmental impact of AI training has emerged as a critical concern in recent years. Large models contribute to substantial carbon footprints, with estimates suggesting that training a single large language model can emit as much CO2 as five cars over their lifetime. The energy consumption extends beyond training to inference, where serving large models at scale requires significant computational resources. Smaller models offer a more sustainable path forward by requiring exponentially less power for both training and deployment. This aligns with growing regulatory and societal pressures for environmentally responsible AI development. Companies are increasingly adopting smaller models not just for cost savings but as part of broader sustainability initiatives, recognizing that AI’s environmental footprint must be minimized to ensure long-term viability.</p>
<h3 id="Accessibility-and-Democratization">Accessibility and Democratization</h3>
<p>Large models often require specialized hardware and infrastructure, creating a significant barrier to entry that limits access to well-funded research institutions and tech giants. The computational requirements of models like GPT-4 necessitate data center-scale infrastructure that few organizations can afford or maintain. Smaller models democratize access to advanced AI capabilities by running on consumer-grade hardware, edge devices, and even mobile phones. This shift enables developers, researchers, and businesses of all sizes to leverage language models without prohibitive infrastructure costs. For example, models like DistilBERT can run on smartphones, opening possibilities for on-device AI applications that preserve user privacy and work offline. This democratization is driving a wave of innovation from diverse sources, as more participants can experiment with and contribute to AI development.</p>
<h3 id="Technical-Advancements-in-Model-Compression">Technical Advancements in Model Compression</h3>
<p>The most immediate driver of smaller LLMs is the rapid advancement in compression techniques and architectural innovations. These technical breakthroughs are making it possible to create models that are orders of magnitude smaller while retaining much of their capabilities.</p>
<p><strong>Quantization Techniques:</strong> Quantization reduces the precision of model weights from 32-bit floating-point to lower precision formats like 8-bit or even 4-bit integers. This can shrink model size by up to 75% with minimal performance loss. Advanced quantization methods like GPTQ (GPT Quantization) and AWQ (Activation-aware Weight Quantization) optimize the quantization process to preserve model accuracy.</p>
<p><strong>Knowledge Distillation:</strong> This technique involves training a smaller “student” model to replicate the behavior of a larger “teacher” model. The student learns to mimic the teacher’s outputs, effectively compressing the knowledge into a more compact form. Recent advancements have extended this to multi-teacher distillation and self-distillation approaches.</p>
<p><strong>Pruning and Sparsity:</strong> Pruning removes unnecessary connections and neurons from neural networks, creating sparse models that can be further compressed. Structured pruning maintains the model’s architecture while unstructured pruning can achieve higher compression ratios. Techniques like magnitude-based pruning and dynamic pruning are becoming increasingly sophisticated.</p>
<p><strong>Efficient Architectures:</strong> New architectural designs specifically target efficiency. Models like MobileBERT and TinyLLaMA incorporate efficient attention mechanisms, grouped convolutions, and optimized layer designs that reduce computational complexity while maintaining expressive power.</p>
<p><strong>Hybrid Approaches:</strong> The most effective compression often combines multiple techniques. For example, a model might undergo knowledge distillation followed by quantization and pruning, achieving compression ratios of 10x or more while retaining 95% of the original performance.</p>
<p>These technical advancements are not just enabling smaller models—they’re fundamentally changing how we think about model design, shifting the focus from maximizing parameters to optimizing efficiency and performance per parameter.</p>
<h2 id="Benefits-The-Advantages-of-Smaller-LLMs">Benefits: The Advantages of Smaller LLMs</h2>
<p>The shift toward smaller LLMs offers numerous advantages that extend beyond mere size reduction.</p>
<h3 id="Improved-Performance-and-Speed">Improved Performance and Speed</h3>
<p>Smaller models often exhibit faster inference times, making them more suitable for real-time applications. In scenarios requiring quick responses, such as chatbots or interactive systems, the reduced latency of compact models provides a significant advantage. This performance improvement is particularly crucial for applications with strict timing requirements.</p>
<h3 id="Enhanced-Deployment-Flexibility">Enhanced Deployment Flexibility</h3>
<p>The compact nature of smaller LLMs enables deployment across a wider range of devices and environments. From cloud servers to edge devices and mobile applications, these models can operate in contexts where larger models would be impractical or impossible. This flexibility opens new use cases, such as on-device language processing for privacy-sensitive applications or offline functionality in remote areas.</p>
<h3 id="Reduced-Resource-Requirements">Reduced Resource Requirements</h3>
<p>Smaller models consume less memory and computational power, making them ideal for resource-constrained environments. This is particularly valuable in developing regions or for applications targeting low-end hardware. The reduced resource footprint also translates to lower operational costs and improved scalability.</p>
<h3 id="Energy-Efficiency-and-Sustainability">Energy Efficiency and Sustainability</h3>
<p>By requiring less computational power, smaller LLMs contribute to reduced energy consumption. This not only lowers operational costs but also aligns with sustainability goals. In an era where AI’s environmental impact is under scrutiny, smaller models offer a more responsible approach to language processing.</p>
<h3 id="Improved-Privacy-and-Security">Improved Privacy and Security</h3>
<p>On-device deployment of smaller models enhances privacy by keeping sensitive data local rather than sending it to remote servers. This is crucial for applications involving personal or confidential information, reducing the risk of data breaches and ensuring compliance with privacy regulations.</p>
<h2 id="Conclusion">Conclusion</h2>
<p>The trend toward smaller LLMs represents a pivotal shift in AI development, driven by the need for efficiency, accessibility, and sustainability. As computational constraints and environmental concerns continue to shape the field, the ability to create powerful yet compact models becomes increasingly valuable. The benefits of smaller LLMs—ranging from improved performance and deployment flexibility to enhanced privacy and reduced environmental impact—position them as a cornerstone of future AI innovation.</p>
<p>This evolution echoes broader themes in AI development, where the pursuit of efficiency and accessibility drives technological progress. As research continues to advance compression techniques and architectural innovations, smaller LLMs are poised to democratize access to advanced language processing capabilities, enabling a wider range of applications and fostering more inclusive AI development.</p>
<!-- commentbox plugin begins -->
    <div class="commentbox"></div>
    <script src="https://unpkg.com/commentbox.io/dist/commentBox.min.js"></script>
    <script>commentBox('5765834504929280-proj')</script>
    <!-- commentbox plugin ends -->
    
        </div>
        <footer class="article-footer">
            
    <a data-url="http://neo01.com/2025/06/The_Shrinking_Frontier_How_Smaller_LLMs_Are_Revolutionizing_AI/" data-id="72e066b7" class="article-share-link"><i class="fa fa-share"></i>Share</a>
<script>
    (function ($) {
        $('body').on('click', function() {
            $('.article-share-box.on').removeClass('on');
        }).on('click', '.article-share-link', function(e) {
            e.stopPropagation();

            var $this = $(this),
                url = $this.attr('data-url').replace("http://","https://"),
                encodedUrl = encodeURIComponent(url),
                id = 'article-share-box-' + $this.attr('data-id'),
                offset = $this.offset(),
                box;

            if ($('#' + id).length) {
                box = $('#' + id);

                if (box.hasClass('on')){
                    box.removeClass('on');
                    return;
                }
            } else {
                var html = [
                    '<div id="' + id + '" class="article-share-box">',
                        '<input class="article-share-input" value="' + url + '">',
                        '<div class="article-share-links">',
                            '<a href="https://twitter.com/intent/tweet?url=' + encodedUrl + '" class="article-share-twitter" target="_blank" title="Twitter"></a>',
                            '<a href="https://www.facebook.com/sharer.php?u=' + encodedUrl + '" class="article-share-facebook" target="_blank" title="Facebook"></a>',
                            '<a href="http://pinterest.com/pin/create/button/?url=' + encodedUrl + '" class="article-share-pinterest" target="_blank" title="Pinterest"></a>',
                        '</div>',
                    '</div>'
                ].join('');

              box = $(html);

              $('body').append(box);
            }

            $('.article-share-box.on').hide();

            box.css({
                top: offset.top + 25,
                left: offset.left
            }).addClass('on');

        }).on('click', '.article-share-box', function (e) {
            e.stopPropagation();
        }).on('click', '.article-share-box-input', function () {
            $(this).select();
        }).on('click', '.article-share-box-link', function (e) {
            e.preventDefault();
            e.stopPropagation();

            window.open(this.href, 'article-share-box-window-' + Date.now(), 'width=500,height=450');
        });
    })(jQuery);
</script>

        </footer>
    </div>
    <!--script type="application/ld+json">
    {
        "@context": "https://schema.org",
        "@type": "BlogPosting",
        "author": {
            "@type": "Person",
            "name": "Neo Alienson"
        },
        "headline": "The Shrinking Frontier: How Smaller LLMs Are Revolutionizing AI",
        "image": "http://neo01.combanner.jpg",
        "keywords": "AI",
        "genre": "AI",
        "datePublished": "2025-06-08",
        "dateCreated": "2025-06-08",
        "dateModified": "2025-09-20",
        "url": "http://neo01.com/2025/06/The_Shrinking_Frontier_How_Smaller_LLMs_Are_Revolutionizing_AI/",
        "description": "
The Shrinking Frontier: How Smaller LLMs Are Revolutionizing AI
In the rapidly evolving landscape of artificial intelligence, Large Language Models (LLMs) have undergone a remarkable transformation. ",
        "wordCount": 1371
    }
</script-->

</article>

                        </div>
                    </section>
                    <aside id="sidebar">
    <a class="sidebar-toggle" title="Expand Sidebar"><i class="toggle icon"></i></a>
    <div class="sidebar-top">
        <p>follow:</p>
        <ul class="social-links">
            
                
                <li>
                    <a class="social-tooltip" title="stack-exchange" href="https://stackexchange.com/users/2122053/neo?tab=accounts" target="_blank" rel="noopener">
                        <i class="icon fa-brands fa-stack-exchange"></i>
                    </a>
                </li>
                
            
                
                <li>
                    <a class="social-tooltip" title="stack-overflow" href="https://stackoverflow.com/users/1885105/neo" target="_blank" rel="noopener">
                        <i class="icon fa-brands fa-stack-overflow"></i>
                    </a>
                </li>
                
            
                
                <li>
                    <a class="social-tooltip" title="github" href="https://github.com/neoalienson" target="_blank" rel="noopener">
                        <i class="icon fa-brands fa-github"></i>
                    </a>
                </li>
                
            
                
                <li>
                    <a class="social-tooltip" title="linkedin" href="https://linkedin.com/in/neo01" target="_blank" rel="noopener">
                        <i class="icon fa-brands fa-linkedin"></i>
                    </a>
                </li>
                
            
                
                <li>
                    <a class="social-tooltip" title="rss" href="/atom.xml" target="_blank" rel="noopener">
                        <i class="icon fa fa-rss"></i>
                    </a>
                </li>
                
            
        </ul>
    </div>
    
        
<nav id="article-nav">
    
        <a href="/2025/07/Architecture_As_Code_Part_1_The_Revolution_Begins/" id="article-nav-newer" class="article-nav-link-wrap">
        <strong class="article-nav-caption">newer</strong>
        <p class="article-nav-title">
        
            Architecture as Code: Part 1 - The Revolution Begins
        
        </p>
        <i class="icon fa fa-chevron-right" id="icon-chevron-right"></i>
    </a>
    
    
        <a href="/2024/12/DevSecOps_Beyond_Tooling_to_Maturity_and_Threat_Modeling/" id="article-nav-older" class="article-nav-link-wrap">
        <strong class="article-nav-caption">older</strong>
        <p class="article-nav-title">DevSecOps - Beyond Tooling to Maturity and Threat Modeling</p>
        <i class="icon fa fa-chevron-left" id="icon-chevron-left"></i>
        </a>
    
</nav>

    
    <div class="widgets-container">
        
            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">links</h3>
        <div class="widget">
            <ul>
                
                    <li>
                        <a href="/ai">AI Playground</a>
                    </li>
                
                    <li>
                        <a href="/tools">Tools</a>
                    </li>
                
                    <li>
                        <a href="/games">Games</a>
                    </li>
                
                    <li>
                        <a href="/pages/useful-information">Useful Information</a>
                    </li>
                
                    <li>
                        <a href="/pages/Hexo-Blogging-Cheatsheet">Hexo Blogging Cheatsheet</a>
                    </li>
                
            </ul>
        </div>
    </div>


            
                
    <div class="widget-wrap">
        <h3 class="widget-title">recents</h3>
        <div class="widget">
            <ul id="recent-post" class="">
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2025/07/Architecture_As_Code_Part_2_Building_the_Foundation/" class="thumbnail">
    
    
        <span style="background-image:url(/2025/07/Architecture_As_Code_Part_2_Building_the_Foundation/thumbnail.jpg)" alt="Architecture as Code: Part 2 - Building the Foundation" class="thumbnail-image"></span>
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/AI/">AI</a></p>
                            <p class="item-title"><a href="/2025/07/Architecture_As_Code_Part_2_Building_the_Foundation/" class="title">Architecture as Code: Part 2 - Building the Foundation</a></p>
                            <p class="item-date"><time datetime="2025-07-19T16:00:00.000Z" itemprop="datePublished">2025-07-20</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2025/07/Architecture_As_Code_Part_1_The_Revolution_Begins/" class="thumbnail">
    
    
        <span style="background-image:url(/2025/07/Architecture_As_Code_Part_1_The_Revolution_Begins/thumbnail.jpg)" alt="Architecture as Code: Part 1 - The Revolution Begins" class="thumbnail-image"></span>
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/AI/">AI</a></p>
                            <p class="item-title"><a href="/2025/07/Architecture_As_Code_Part_1_The_Revolution_Begins/" class="title">Architecture as Code: Part 1 - The Revolution Begins</a></p>
                            <p class="item-date"><time datetime="2025-07-14T16:00:00.000Z" itemprop="datePublished">2025-07-15</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2025/06/The_Shrinking_Frontier_How_Smaller_LLMs_Are_Revolutionizing_AI/" class="thumbnail">
    
    
        <span style="background-image:url(/2025/06/The_Shrinking_Frontier_How_Smaller_LLMs_Are_Revolutionizing_AI/thumbnail.jpg)" alt="The Shrinking Frontier: How Smaller LLMs Are Revolutionizing AI" class="thumbnail-image"></span>
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/AI/">AI</a></p>
                            <p class="item-title"><a href="/2025/06/The_Shrinking_Frontier_How_Smaller_LLMs_Are_Revolutionizing_AI/" class="title">The Shrinking Frontier: How Smaller LLMs Are Revolutionizing AI</a></p>
                            <p class="item-date"><time datetime="2025-06-07T16:00:00.000Z" itemprop="datePublished">2025-06-08</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2024/12/DevSecOps_Beyond_Tooling_to_Maturity_and_Threat_Modeling/" class="thumbnail">
    
    
        <span class="thumbnail-image thumbnail-none"></span>
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/Development/">Development</a></p>
                            <p class="item-title"><a href="/2024/12/DevSecOps_Beyond_Tooling_to_Maturity_and_Threat_Modeling/" class="title">DevSecOps - Beyond Tooling to Maturity and Threat Modeling</a></p>
                            <p class="item-date"><time datetime="2024-11-30T16:00:00.000Z" itemprop="datePublished">2024-12-01</time></p>
                        </div>
                    </li>
                
                    <li>
                        
                        <div class="item-thumbnail">
                            <a href="/2024/11/Attestation-Centric-Dev-Sec-Ops-Fortifying-Enterprise-Software-Development/" class="thumbnail">
    
    
        <span style="background-image:url(/2024/11/Attestation-Centric-Dev-Sec-Ops-Fortifying-Enterprise-Software-Development/icon.png)" alt="Attestation-Centric DevSecOps - Fortifying Enterprise Software Development" class="thumbnail-image"></span>
    
</a>

                        </div>
                        
                        <div class="item-inner">
                            <p class="item-category"><a class="article-category-link" href="/categories/Cybersecurity/">Cybersecurity</a></p>
                            <p class="item-title"><a href="/2024/11/Attestation-Centric-Dev-Sec-Ops-Fortifying-Enterprise-Software-Development/" class="title">Attestation-Centric DevSecOps - Fortifying Enterprise Software Development</a></p>
                            <p class="item-date"><time datetime="2024-11-15T16:00:00.000Z" itemprop="datePublished">2024-11-16</time></p>
                        </div>
                    </li>
                
            </ul>
        </div>
    </div>

            
                
    <div class="widget-wrap widget-list">
        <h3 class="widget-title">archives</h3>
        <div class="widget">
            <ul class="archive-list"><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/07/">July 2025</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2025/06/">June 2025</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/12/">December 2024</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/11/">November 2024</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/10/">October 2024</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/07/">July 2024</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/06/">June 2024</a><span class="archive-list-count">12</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/05/">May 2024</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/02/">February 2024</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2024/01/">January 2024</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/12/">December 2023</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/10/">October 2023</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/09/">September 2023</a><span class="archive-list-count">3</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/08/">August 2023</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/05/">May 2023</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/04/">April 2023</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2023/03/">March 2023</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2022/12/">December 2022</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/03/">March 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2018/01/">January 2018</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/12/">December 2017</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/07/">July 2017</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2017/05/">May 2017</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/11/">November 2016</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/06/">June 2016</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/03/">March 2016</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2016/02/">February 2016</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/12/">December 2015</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/10/">October 2015</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/05/">May 2015</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/04/">April 2015</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2015/03/">March 2015</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/12/">December 2014</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/08/">August 2014</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/07/">July 2014</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/03/">March 2014</a><span class="archive-list-count">2</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2014/01/">January 2014</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2013/07/">July 2013</a><span class="archive-list-count">1</span></li><li class="archive-list-item"><a class="archive-list-link" href="/archives/2013/01/">January 2013</a><span class="archive-list-count">1</span></li></ul>
        </div>
    </div>


            
                
    <div class="widget-wrap widget-float">
        <h3 class="widget-title">tag cloud</h3>
        <div class="widget tagcloud">
            <a href="/tags/3D-printing/" style="font-size: 10px;">3D printing</a> <a href="/tags/AI/" style="font-size: 20px;">AI</a> <a href="/tags/Android/" style="font-size: 12.5px;">Android</a> <a href="/tags/Apple/" style="font-size: 12.5px;">Apple</a> <a href="/tags/Architecture/" style="font-size: 12.5px;">Architecture</a> <a href="/tags/Assembly/" style="font-size: 10px;">Assembly</a> <a href="/tags/Azure/" style="font-size: 10px;">Azure</a> <a href="/tags/C/" style="font-size: 10px;">C#</a> <a href="/tags/Cybersecurity/" style="font-size: 10px;">Cybersecurity</a> <a href="/tags/DevSecOps/" style="font-size: 10px;">DevSecOps</a> <a href="/tags/GitOps/" style="font-size: 10px;">GitOps</a> <a href="/tags/Go/" style="font-size: 10px;">Go</a> <a href="/tags/Google/" style="font-size: 12.5px;">Google</a> <a href="/tags/Groovy/" style="font-size: 10px;">Groovy</a> <a href="/tags/Hacking/" style="font-size: 10px;">Hacking</a> <a href="/tags/Home-Assistant/" style="font-size: 10px;">Home Assistant</a> <a href="/tags/Java/" style="font-size: 12.5px;">Java</a> <a href="/tags/Jenkins/" style="font-size: 10px;">Jenkins</a> <a href="/tags/Mac/" style="font-size: 12.5px;">Mac</a> <a href="/tags/MacOS/" style="font-size: 10px;">MacOS</a> <a href="/tags/Minecraft/" style="font-size: 12.5px;">Minecraft</a> <a href="/tags/Open-Data/" style="font-size: 10px;">Open Data</a> <a href="/tags/PHP/" style="font-size: 10px;">PHP</a> <a href="/tags/Python/" style="font-size: 10px;">Python</a> <a href="/tags/Security/" style="font-size: 10px;">Security</a> <a href="/tags/ShellScript/" style="font-size: 10px;">ShellScript</a> <a href="/tags/Software-Engineering/" style="font-size: 10px;">Software Engineering</a> <a href="/tags/Swift/" style="font-size: 15px;">Swift</a> <a href="/tags/Test-Automation/" style="font-size: 10px;">Test Automation</a> <a href="/tags/Visualization/" style="font-size: 10px;">Visualization</a> <a href="/tags/arm/" style="font-size: 12.5px;">arm</a> <a href="/tags/cloud/" style="font-size: 10px;">cloud</a> <a href="/tags/docker/" style="font-size: 10px;">docker</a> <a href="/tags/enterprise/" style="font-size: 10px;">enterprise</a> <a href="/tags/hackathon/" style="font-size: 12.5px;">hackathon</a> <a href="/tags/iOS/" style="font-size: 17.5px;">iOS</a> <a href="/tags/jasmine/" style="font-size: 10px;">jasmine</a> <a href="/tags/javascript/" style="font-size: 10px;">javascript</a> <a href="/tags/nodejs/" style="font-size: 12.5px;">nodejs</a> <a href="/tags/python/" style="font-size: 10px;">python</a> <a href="/tags/terraform/" style="font-size: 15px;">terraform</a> <a href="/tags/wdcloud/" style="font-size: 12.5px;">wdcloud</a> <a href="/tags/wifi/" style="font-size: 10px;">wifi</a>
        </div>
    </div>


            
        
    </div>
</aside>

                </div>
            </div>
        </div>
        <footer id="footer">
    <div class="container">
        <div class="container-inner">
            <a id="back-to-top" href="javascript:;"><i class="icon fa fa-angle-up"></i></a>
            <div class="credit">
                <h1 class="logo-wrap">
                    <a href="/" title="Homepage" class="logo"></a>
                </h1>
                <p>© 2025 Neo Alienson
                  <a href="/terms-and-conditions">Terms and Condition</a></p>
                
            </div>
            <div class="footer-plugins">
              


            </div>
        </div>
    </div>
</footer>

        
    
        


        


        


        


        


        


        


        


        


    



<!-- Custom Scripts -->




    </div>
<!-- hexo injector body_end start --><script type="text/javascript" src="/js/bundle_last.js"></script><!-- hexo injector body_end end -->

</body></html>